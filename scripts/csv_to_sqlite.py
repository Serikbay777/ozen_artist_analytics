#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV —Ñ–∞–π–ª–æ–≤ –≤ SQLite –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ë–î, –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö CSV
"""

import pandas as pd
import sqlite3
import os
import glob
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))


def create_database(data_dir='data/processed', db_path='data/analytics.db', force=False):
    """
    –°–æ–∑–¥–∞—ë—Ç SQLite –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–æ–≤
    
    Args:
        data_dir: –ü–∞–ø–∫–∞ —Å CSV —Ñ–∞–π–ª–∞–º–∏
        db_path: –ü—É—Ç—å –∫ SQLite –±–∞–∑–µ
        force: –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ë–î –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    """
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ë–î
    if os.path.exists(db_path) and not force:
        print(f"‚ö†Ô∏è  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {db_path}")
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è")
        return
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –ë–î –µ—Å–ª–∏ force=True
    if os.path.exists(db_path) and force:
        os.remove(db_path)
        print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ CSV —Ñ–∞–π–ª—ã
    csv_files = glob.glob(os.path.join(data_dir, '*.csv'))
    
    if not csv_files:
        print(f"‚ùå CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {data_dir}")
        return
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(csv_files)} CSV —Ñ–∞–π–ª–æ–≤")
    print(f"üéØ –°–æ–∑–¥–∞—ë–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {db_path}")
    print()
    
    # –°–æ–∑–¥–∞—ë–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    conn = sqlite3.connect(db_path)
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
    dtypes = {
        '–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å': 'category',
        '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞': 'category',
        '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞': 'category',
        '—Å—Ç—Ä–∞–Ω–∞ / —Ä–µ–≥–∏–æ–Ω': 'category',
        '–õ–µ–π–±–ª': 'category',
        '–¢–∏–ø –ø—Ä–æ–¥–∞–∂–∏': 'category',
        '–¢–∏–ø —Ä–µ–ª–∏–∑–∞': 'category',
        '–ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–ª–∏–∑–∞': 'category'
    }
    
    # –ö–æ–ª–æ–Ω–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–º –Ω—É–∂–Ω—ã
    usecols = [
        '–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞',
        '–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å',
        '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞',
        '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞',
        '–°—É–º–º–∞ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è',
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ',
        '—Å—Ç—Ä–∞–Ω–∞ / —Ä–µ–≥–∏–æ–Ω',
        '–õ–µ–π–±–ª',
        '–¢–∏–ø –ø—Ä–æ–¥–∞–∂–∏'
    ]
    
    total_rows = 0
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—ã–π CSV —Ñ–∞–π–ª
    for csv_file in csv_files:
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞: {os.path.basename(csv_file)}")
        
        try:
            # –ß–∏—Ç–∞–µ–º CSV —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
            df = pd.read_csv(
                csv_file,
                sep=';',
                usecols=lambda x: x in usecols,
                dtype=dtypes,
                low_memory=False
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
            df['–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞'] = pd.to_datetime(df['–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞'], errors='coerce')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            df['year'] = df['–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞'].dt.year
            df['month'] = df['–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞'].dt.month
            df['quarter'] = df['–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞'].dt.quarter
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ SQLite
            df.to_sql(
                'analytics',
                conn,
                if_exists='append',
                index=False,
                chunksize=10000  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ —á–∞—Å—Ç—è–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            )
            
            total_rows += len(df)
            print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} —Å—Ç—Ä–æ–∫")
            
        except Exception as e:
            print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
    
    print()
    print(f"üìä –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {total_rows:,} —Å—Ç—Ä–æ–∫")
    print()
    print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤...")
    
    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    indexes = [
        ("idx_artist", "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å"),
        ("idx_track", "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞"),
        ("idx_platform", "–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞"),
        ("idx_country", "—Å—Ç—Ä–∞–Ω–∞ / —Ä–µ–≥–∏–æ–Ω"),
        ("idx_date", "–ú–µ—Å—è—Ü –æ—Ç—á–µ—Ç–∞"),
        ("idx_year", "year"),
        ("idx_label", "–õ–µ–π–±–ª"),
    ]
    
    for idx_name, column in indexes:
        try:
            conn.execute(f'CREATE INDEX IF NOT EXISTS {idx_name} ON analytics("{column}")')
            print(f"   ‚úì –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å: {idx_name}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –ò–Ω–¥–µ–∫—Å {idx_name}: {e}")
    
    # –°–æ–∑–¥–∞—ë–º —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    try:
        conn.execute('CREATE INDEX IF NOT EXISTS idx_artist_track ON analytics("–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å", "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞")')
        print(f"   ‚úì –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å: idx_artist_track")
    except:
        pass
    
    conn.commit()
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –ë–î
    db_size = os.path.getsize(db_path) / (1024 * 1024)
    
    print()
    print("=" * 60)
    print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
    print(f"üìÅ –ü—É—Ç—å: {db_path}")
    print(f"üíæ –†–∞–∑–º–µ—Ä: {db_size:.1f} MB")
    print(f"üìä –°—Ç—Ä–æ–∫: {total_rows:,}")
    print("=" * 60)
    
    conn.close()


def update_database(data_dir='data/processed', db_path='data/analytics.db'):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤—ã–º–∏ CSV —Ñ–∞–π–ª–∞–º–∏
    (–ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è - –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë—Ç –ë–î)
    """
    print("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    create_database(data_dir, db_path, force=True)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV –≤ SQLite')
    parser.add_argument('--data-dir', default='data/processed', help='–ü–∞–ø–∫–∞ —Å CSV —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--db-path', default='data/analytics.db', help='–ü—É—Ç—å –∫ SQLite –±–∞–∑–µ')
    parser.add_argument('--force', action='store_true', help='–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ë–î')
    parser.add_argument('--update', action='store_true', help='–û–±–Ω–æ–≤–∏—Ç—å –ë–î')
    
    args = parser.parse_args()
    
    if args.update:
        update_database(args.data_dir, args.db_path)
    else:
        create_database(args.data_dir, args.db_path, args.force)

